import os
import yaml
import torch
import time
import numpy as np
import argparse
from core.data_loader import create_loaders, SkillIconDataset
from core.model_builder import create_model
from utils.logger import MetricLogger
from torch.utils.data import DataLoader
import onnxruntime as ort

def main():
    # å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description="éªŒè¯è„šæœ¬ï¼Œå¯æŒ‡å®šéªŒè¯é›†è·¯å¾„")
    parser.add_argument("--val_path", type=str, default="", help="æŒ‡å®šéªŒè¯é›†è·¯å¾„")
    args = parser.parse_args()

    # 1. åŠ è½½é…ç½®æ–‡ä»¶
    config_path = os.environ.get('CONFIG_PATH', "configs/mobilenetv4.yaml")
    try:
        with open(config_path, encoding='utf-8') as f:
            config = yaml.safe_load(f)
        print("âœ… é…ç½®æ–‡ä»¶åŠ è½½å®Œæˆ")
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨")
        return

    # 2. åˆå§‹åŒ–è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"âš™ï¸ ä½¿ç”¨è®¾å¤‡: {device}")

    # 3. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    try:
        model_wrapper = create_model(config)
        if args.val_path:
            # ä»æŒ‡å®šè·¯å¾„åˆ›å»º val_loader
            val_dataset = SkillIconDataset(
                root_dir=args.val_path,
                transform=model_wrapper.val_transform
            )
            
            val_loader = DataLoader(
                val_dataset,
                batch_size=int(config['training']['batch_size']) * 2,
                shuffle=False,
                num_workers=4,
                pin_memory=True
            )
            print(f"ğŸ“Š æ•°æ®åŠ è½½å™¨ç»Ÿè®¡ | æŒ‡å®šéªŒè¯é›†è·¯å¾„: {args.val_path} | éªŒè¯é›†æ ·æœ¬: {len(val_loader.dataset)} | æ‰¹æ¬¡: {len(val_loader)}")
        else:
            # ä½¿ç”¨ create_loaders å‡½æ•°
            train_loader, val_loader = create_loaders(
                config,
                train_transform=model_wrapper.train_transform,
                val_transform=model_wrapper.val_transform
            )
            print(f"ğŸ“Š æ•°æ®åŠ è½½å™¨ç»Ÿè®¡ | éªŒè¯é›†æ ·æœ¬: {len(val_loader.dataset)} | æ‰¹æ¬¡: {len(val_loader)}")
    except KeyError as e:
        print(f"âŒ æ•°æ®åŠ è½½é…ç½®é”™è¯¯: {str(e)}")
        return

    # 4. åˆå§‹åŒ– ONNX æ¨¡å‹
    try:
        onnx_path = "checkpoints/mobilenetv4.onnx"
        if not os.path.exists(onnx_path):
            raise FileNotFoundError(f"ONNX æ¨¡å‹æ–‡ä»¶ {onnx_path} ä¸å­˜åœ¨")
        
        ort_session = ort.InferenceSession(onnx_path)
        print(f"ğŸš€ ONNX æ¨¡å‹åŠ è½½å®Œæˆ: {onnx_path}")
    except Exception as e:
        print(f"âŒ ONNX æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        return

    # 5. åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨
    logger = MetricLogger(
        log_dir=os.path.join("eval_logs", config['model']['name']),
        class_names=['c', 'n', 'y'],
        model_name=config['model']['name'],
        class_weights=None
    )

    # 6. æ¨ç†æ€§èƒ½æµ‹è¯•
    try:
        input_size = config['data']['input_size']
        
        # è‡ªåŠ¨å¤„ç†ä¸åŒè¾“å…¥æ ¼å¼
        if isinstance(input_size, int):
            input_size = [input_size, input_size]
            print(f"âš ï¸  å·²è‡ªåŠ¨è½¬æ¢ input_size ä¸º {input_size}")
        elif isinstance(input_size, (list, tuple)) and len(input_size) == 1:
            input_size = list(input_size) * 2
            print(f"âš ï¸  å·²è‡ªåŠ¨æ‰©å±• input_size ä¸º {input_size}")
            
        dummy_input = torch.randn(1, 3, *input_size).numpy().astype(np.float32)
        
        # æµ‹é€Ÿé€»è¾‘
        warmup_iters = 10
        test_iters = 100
        
        print("â±ï¸ å¼€å§‹æ¨ç†é€Ÿåº¦æµ‹è¯•...")
        
        # Get input and output names
        input_name = ort_session.get_inputs()[0].name
        output_name = ort_session.get_outputs()[0].name
        
        # Warmup
        for _ in range(warmup_iters):
            ort_session.run([output_name], {input_name: dummy_input})
        
        # æ­£å¼æµ‹é€Ÿ
        start_time = time.time()
        for _ in range(test_iters):
            ort_session.run([output_name], {input_name: dummy_input})
        avg_latency = (time.time() - start_time) * 1000 / test_iters
        print(f"ğŸš€ ONNX æ¨ç†é€Ÿåº¦ | å¹³å‡å»¶è¿Ÿ: {avg_latency:.2f}ms | FPS: {1000/avg_latency:.1f}")
    except KeyError:
        print("âŒ é…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘ input_size å®šä¹‰ï¼Œä½¿ç”¨é»˜è®¤å°ºå¯¸ 64x64")
        dummy_input = torch.randn(1, 3, 64, 64).numpy().astype(np.float32)
        avg_latency = 0

    # 7. å®Œæ•´éªŒè¯æµç¨‹
    print("\nğŸ” å¼€å§‹å®Œæ•´éªŒè¯...")
    logger.new_epoch()
    total_samples = 0

    # è¾“å‡ºæ–‡ä»¶è·¯å¾„
    output_file = None
    if args.val_path:
        output_file = open("onnx_results.txt", "w", encoding="utf-8")

    try:
        with torch.no_grad():
            for batch_idx, (images, labels) in enumerate(val_loader):
                images, labels = images.to(device), labels.to(device)
                
                # ONNX æ¨ç†
                input_name = ort_session.get_inputs()[0].name
                outputs = ort_session.run(None, {input_name: images.to(torch.device('cpu')).numpy()})[0]
                outputs = torch.from_numpy(outputs).to(device)
                outputs = torch.softmax(outputs, dim=1)
                
                logger.log_val(0, outputs, labels)
                total_samples += labels.size(0)

                if batch_idx == 0:
                    print(f"ğŸ“¦ é¦–æ‰¹æ¬¡æ•°æ® | è¾“å…¥å½¢çŠ¶: {images.shape} | è¾“å‡ºå½¢çŠ¶: {outputs.shape}")

                # è¾“å‡ºç»“æœåˆ°æ–‡ä»¶
                if output_file:
                    probs = torch.softmax(outputs, dim=1)
                    for i in range(images.size(0)):
                        image_path = val_loader.dataset.samples[batch_idx * config['training']['batch_size'] + i][0]
                        pred_class = torch.argmax(probs[i]).item()
                        true_class = labels[i].item()
                        class_probs = probs[i].tolist()
                        output_file.write(f"å›¾ç‰‡è·¯å¾„: {image_path}\n")
                        output_file.write(f"é¢„æµ‹ç±»åˆ«: {pred_class}\n")
                        output_file.write(f"æ ‡ç­¾ç±»åˆ«: {true_class}\n")
                        output_file.write(f"ç±»åˆ«ç½®ä¿¡åº¦: {[f'{p:.8f}' for p in class_probs]}\n")
                        output_file.write("-" * 50 + "\n")

        print(f"ğŸ“¥ å·²éªŒè¯æ ·æœ¬æ€»æ•°: {total_samples}")
    except RuntimeError as e:
        print(f"âŒ éªŒè¯è¿‡ç¨‹å¼‚å¸¸: {str(e)}")
        return
    finally:
        if output_file:
            output_file.close()
            print("ğŸ“ éªŒè¯ç»“æœå·²ä¿å­˜åˆ° onnx_results.txt")

    # 8. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    logger.finalize_val()
    if 'accuracy' in logger.val_metrics:
        print(f"\nğŸ“ˆ éªŒè¯ç»“æœ | å‡†ç¡®ç‡: {logger.val_metrics['accuracy']:.2%}")
    else:
        print("âš ï¸ æœªè®¡ç®—éªŒè¯æŒ‡æ ‡ï¼Œè¯·æ£€æŸ¥æ•°æ®è®°å½•")

if __name__ == "__main__":
    main()
