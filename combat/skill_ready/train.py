import os
import yaml
import torch
import torch.nn as nn
import torch.optim as optim
import argparse
from torch.utils.tensorboard import SummaryWriter
from core.data_loader import create_loaders  # å¯¼å…¥æ•°æ®åŠ è½½å™¨
from core.base_model import BaseModel  # å¯¼å…¥åŸºç¡€æ¨¡å‹ç±»
from core.model_builder import create_model  # å¯¼å…¥æ¨¡å‹åˆ›å»ºå‡½æ•°
from utils.logger import MetricLogger  # å¯¼å…¥æ—¥å¿—è®°å½•å™¨
from torch.amp import autocast, GradScaler
from utils.path_manager import get_model_paths

def parse_args():
    parser = argparse.ArgumentParser(description='Train model scripts')
    parser.add_argument('--config', help='æŒ‡å®šæ¨¡å‹é…ç½®æ–‡ä»¶', default='configs/mobilenetv4_conv_small.yaml', type=str, required=True)
    args = parser.parse_args()
    return args


def main():
    args = parse_args()

    # 1. åŠ è½½é…ç½®æ–‡ä»¶
    try:
        with open(args.config, encoding='utf-8') as f:
            config = yaml.safe_load(f)
        print("âœ… é…ç½®æ–‡ä»¶åŠ è½½å®Œæˆ")
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯ï¼šé…ç½®æ–‡ä»¶ {args.config} ä¸å­˜åœ¨")
        return

    # 2. åˆå§‹åŒ–è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")  # å¦‚æœ GPU å¯ç”¨ï¼Œåˆ™ä½¿ç”¨ GPUï¼Œå¦åˆ™ä½¿ç”¨ CPU
    print(f"âš™ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    paths = get_model_paths(config)

    # 3. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    try:
        model_wrapper = create_model(config) # åˆ›å»ºæ¨¡å‹åŒ…è£…å™¨
        print("âœ… åˆ›å»ºæ¨¡å‹åŒ…è£…å™¨å®Œæˆ")
        train_loader, val_loader = create_loaders(  # åˆ›å»ºè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ•°æ®åŠ è½½å™¨
            config,  # ä¼ é€’æ•°æ®ç›¸å…³çš„é…ç½®
            train_transform=model_wrapper.train_transform,  # ä¼ é€’è®­ç»ƒé›†çš„æ•°æ®å¢å¼º
            val_transform=model_wrapper.val_transform  # ä¼ é€’éªŒè¯é›†çš„æ•°æ®å¢å¼º
        )
        print("âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ")
    except KeyError as e:
        print(f"âŒ æ•°æ®åŠ è½½é…ç½®é”™è¯¯: {str(e)}")
        return
    
    # 4. åˆå§‹åŒ–æ¨¡å‹
    try:
        model = create_model(config).to(device)  # ä½¿ç”¨æ¨¡å‹åˆ›å»ºå‡½æ•°åˆ›å»ºæ¨¡å‹ï¼Œå¹¶å°†å…¶ç§»åŠ¨åˆ°æŒ‡å®šçš„è®¾å¤‡ä¸Š
        print("ğŸš€ æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return

    # 5. åˆå§‹åŒ–ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    try:
        try:
            optim_type = config['training']['optimizer']['type']
            optimizer_cls = getattr(optim, optim_type)  # æ ¹æ® config è®¾ç½®ä¼˜åŒ–å™¨ç±»å‹ï¼Œä¾‹å¦‚ AdamW
        except AttributeError:
            print(f"âš ï¸ ä¼˜åŒ–å™¨ {optim_type} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤çš„ AdamW")
            optimizer_cls = optim.AdamW

        optimizer = optimizer_cls(
            model.parameters(),  # ä¼ é€’æ¨¡å‹çš„æ‰€æœ‰å‚æ•°
            lr=float(config['training']['optimizer']['lr']),  # ä¼ é€’å­¦ä¹ ç‡
            weight_decay=float(config['training']['optimizer']['weight_decay'])  # ä¼ é€’æƒé‡è¡°å‡ç³»æ•°
        )
        print("âœ… ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        print(f"âŒ ä¼˜åŒ–å™¨æˆ–æŸå¤±å‡½æ•°åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return

    # 6. å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
    criterion = nn.CrossEntropyLoss(weight=None)  # ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œå¹¶ä¼ é€’ç±»åˆ«æƒé‡

    # 7. æ··åˆç²¾åº¦è®­ç»ƒ
    try:
        use_cuda_amp = config['training']['use_cuda_amp']
        if use_cuda_amp:
            scaler = GradScaler('cuda')  # åˆ›å»º GradScaler å¯¹è±¡ï¼Œç”¨äºæ··åˆç²¾åº¦è®­ç»ƒ
            print("ğŸ”§ ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ")
    except Exception as e:
        print(f"âŒ ä¸æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒæˆ–å¯åŠ¨é”™è¯¯: {str(e)}")
        return

    # 8. æ—¥å¿—è®°å½•
    logger = MetricLogger(  # åˆ›å»º MetricLogger å¯¹è±¡ï¼Œç”¨äºè®°å½•è®­ç»ƒå’ŒéªŒè¯æŒ‡æ ‡
        log_dir="train",  # æŒ‡å®šæ—¥å¿—ç›®å½•
        class_names=['c', 'n', 'y'],  # æŒ‡å®šç±»åˆ«åç§°
        model_name=config['model']['name'], # æŒ‡å®šæ¨¡å‹åç§°
        class_weights=None # class_weights.cpu().numpy() if torch.cuda.is_available() else class_weights.numpy()
    )

    # 9. è®­ç»ƒå¾ªç¯
    best_acc = 0.0  # åˆå§‹åŒ–æœ€ä½³éªŒè¯é›†å‡†ç¡®ç‡
    for epoch in range(config['training']['epochs']):  # éå†æ‰€æœ‰ epoch
        print()
        print(f"ğŸ“¦ Epoch {epoch+1} å¼€å§‹")
        # è®­ç»ƒé˜¶æ®µ
        model.train()  # å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
        logger.new_epoch()  # å¼€å§‹æ–°çš„ epoch

        for i, (images, labels) in enumerate(train_loader):  # éå†è®­ç»ƒé›†çš„æ•°æ®åŠ è½½å™¨
            images, labels = images.to(device), labels.to(device)  # å°†å›¾åƒå’Œæ ‡ç­¾ç§»åŠ¨åˆ°æŒ‡å®šçš„è®¾å¤‡ä¸Š

            if use_cuda_amp:
                with autocast('cuda'):
                    outputs = model(images)
                    loss = criterion(outputs, labels.long())
            else:
                outputs = model(images)
                loss = criterion(outputs, labels.long())

            if use_cuda_amp:
                scaler.scale(loss).backward()  # åå‘ä¼ æ’­æŸå¤±
                scaler.step(optimizer)  # æ›´æ–°ä¼˜åŒ–å™¨
                scaler.update()  # æ›´æ–° GradScaler
            else:
                loss.backward()
                optimizer.step()
            optimizer.zero_grad()  # æ¸…ç©ºæ¢¯åº¦

            # è®°å½•æŒ‡æ ‡
            logger.log_train(loss.item(), outputs, labels)  # è®°å½•è®­ç»ƒæŸå¤±ã€è¾“å‡ºå’Œæ ‡ç­¾
            if (i+1) % 10 == 0:
                print(f"    Batch {i+1}/{len(train_loader)} å®Œæˆ")

        # éªŒè¯é˜¶æ®µ
        model.eval()  # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—
            for images, labels in val_loader:  # éå†éªŒè¯é›†çš„æ•°æ®åŠ è½½å™¨
                images, labels = images.to(device), labels.to(device)  # å°†å›¾åƒå’Œæ ‡ç­¾ç§»åŠ¨åˆ°æŒ‡å®šçš„è®¾å¤‡ä¸Š

                if use_cuda_amp:
                    with autocast('cuda'):
                        outputs = model(images)
                        loss = criterion(outputs, labels.long())
                else:
                    outputs = model(images)
                    loss = criterion(outputs, labels.long())

                # è®°å½•æŒ‡æ ‡
                logger.log_val(loss.item(), outputs, labels)  # è®°å½•éªŒè¯æŸå¤±ã€è¾“å‡ºå’Œæ ‡ç­¾

        # 10. åˆ›å»º checkpoints ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        checkpoint_dir = "checkpoints"  # æŒ‡å®š checkpoints ç›®å½•
        os.makedirs(checkpoint_dir, exist_ok=True)  # åˆ›å»ºç›®å½•ï¼Œå¦‚æœç›®å½•å·²å­˜åœ¨åˆ™ä¸æŠ¥é”™

        # 11. ä¿å­˜æœ€ä½³æ¨¡å‹
        logger.finalize_epoch()
        if logger.val_metrics['accuracy'] > best_acc:  # å¦‚æœå½“å‰éªŒè¯é›†å‡†ç¡®ç‡å¤§äºæœ€ä½³éªŒè¯é›†å‡†ç¡®ç‡
            best_acc = logger.val_metrics['accuracy']  # æ›´æ–°æœ€ä½³éªŒè¯é›†å‡†ç¡®ç‡
            torch.save(model.state_dict(), paths["checkpoint_export"])  # ä¿å­˜æ¨¡å‹çš„çŠ¶æ€å­—å…¸
        
        # ç”ŸæˆæŠ¥å‘Š
        print(f"Epoch {epoch+1} å®Œæˆï¼ŒéªŒè¯é›†å‡†ç¡®ç‡: {logger.val_metrics['accuracy']:.4f}")

if __name__ == "__main__":
    main()  # å¦‚æœæ˜¯ä¸»ç¨‹åºï¼Œåˆ™æ‰§è¡Œ main å‡½æ•°
